[{"question":"What is the primary purpose of Apache Kafka?","answers":["To manage distributed logging","To provide high-throughput, low-latency platform for handling real-time data feeds","To store large amounts of data","To analyze data streams"],"correct":1,"translations":{"it":["Per cosa viene utilizzato principalmente Amazon S3?","Gestire la registrazione distribuita","Fornire una piattaforma ad alta velocità e bassa latenza per gestire flussi di dati in tempo reale","Conservare grandi quantità di dati","Analizzare flussi di dati"]}},{"question":"What is a Kafka partition?","answers":["A segment of data that is written in multiple formats","A unit of parallelism in Kafka","A temporary storage area for Kafka events","A mechanism to split Kafka clusters"],"correct":1,"translations":{"it":["Quale servizio AWS è progettato per analisi scalabili di data warehouse?","Un segmento di dati scritto in formati multipli","Un'unità di parallelismo in Kafka","Un'area di archiviazione temporanea per gli eventi di Kafka","Un meccanismo per suddividere i cluster di Kafka"]}},{"question":"How does Kafka achieve fault tolerance?","answers":["By replicating messages to multiple brokers","By using erasure coding","By storing data in a distributed file system","By applying transaction logs"],"correct":0,"translations":{"it":["Come puoi gestire in modo sicuro l'accesso ai servizi e alle risorse AWS?","Replica i messaggi su più broker","Utilizzando il coding di cancellazione","Archiviando i dati in un file system distribuito","Applicando registri di transazioni"]}},{"question":"Which command is used to create a Kafka topic?","answers":["kafka-create-topic","kafka-config-topic","kafka-topics.sh --create","kafka-init-topic"],"correct":2,"translations":{"it":["Quale dei seguenti è un servizio di calcolo serverless completamente gestito in AWS?","kafka-create-topic","kafka-config-topic","kafka-topics.sh --create","kafka-init-topic"]}},{"question":"What does ISR stand for in Kafka terminology?","answers":["In Sync Replicas","Initial State Recovery","Immediate Sequential Read","Indexed Synchronized Record"],"correct":0,"translations":{"it":["Che tipo di servizio è Amazon EC2?","Repliche Sincronizzate","Recupero Stato Iniziale","Lettura Sequenziale Immediata","Record Indicizzato Sincronizzato"]}},{"question":"Use the below code to identify which part of Kafka it pertains to.","answers":["Producer API","Consumer API","Kafka Stream API","AdminClient API"],"correct":1,"code":"import org.apache.kafka.clients.consumer.ConsumerRecord;\nimport org.apache.kafka.clients.consumer.KafkaConsumer;\n\nimport java.util.Arrays;\nimport java.util.Properties;\n\npublic class KafkaConsumerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"group.id\", \"test-group\");\n        props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Arrays.asList(\"test-topic\"));\n\n        try {\n            while (true) {\n                for (ConsumerRecord<String, String> record : consumer.poll(100)) {\n                    System.out.println(\"offset = \" + record.offset() + \", key = \" + record.key() + \", value = \" + record.value());\n                }\n            }\n        } finally {\n            consumer.close();\n        }\n    }\n}","translations":{"it":["Cosa farà il seguente comando AWS CLI?","Producer API","Consumer API","Kafka Stream API","AdminClient API"]}},{"question":"Review the following code snippet and specify its purpose in Kafka.","answers":["Sending a message to a Kafka topic","Creating a Kafka stream","Consuming messages from a Kafka topic","Managing Kafka topics"],"correct":0,"code":"import org.apache.kafka.clients.producer.KafkaProducer;\nimport org.apache.kafka.clients.producer.ProducerRecord;\n\nimport java.util.Properties;\n\npublic class KafkaProducerExample {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"localhost:9092\");\n        props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n        KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n        \n        for (int i = 0; i < 10; i++) {\n            ProducerRecord<String, String> record = new ProducerRecord<>(\"test-topic\", \"key-\" + i, \"value-\" + i);\n            producer.send(record);\n        }\n\n        producer.close();\n    }\n}","translations":{"it":["In un template CloudFormation, qual è lo scopo della sezione 'Resources'?","Invio di un messaggio a un topic Kafka","Creazione di uno stream Kafka","Consumo di messaggi da un topic Kafka","Gestione dei topic Kafka"]}},{"question":"What is the role of Kafka Connect?","answers":["To add data to a messaging queue","To facilitate data import/export between Kafka and other systems","To connect multiple Kafka clusters","To monitor Kafka performance"],"correct":1,"translations":{"it":["Quale sarà il risultato della seguente policy JSON?","Aggiungere dati a una coda di messaggistica","Facilitare l'import/export di dati tra Kafka e altri sistemi","Collegare più cluster Kafka","Monitorare le prestazioni di Kafka"]}},{"question":"What function does the 'offset' fulfill in Kafka?","answers":["It labels messages with unique IDs","It determines the order of message consumption","It manages Kafka cluster leader elections","It retrieves consumer group information"],"correct":1,"translations":{"it":["Cosa creerà il seguente codice CloudFormation?","Etichetta i messaggi con ID unici","Determina l'ordine di consumo dei messaggi","Gestisce le elezioni del leader del cluster Kafka","Recupera le informazioni dei gruppi di consumatori"]}},{"question":"Examine the following code snippet. Which component of Kafka does it represent?","answers":["Kafka Producer","Kafka AdminClient","Kafka Zookeeper","Kafka Streams"],"correct":3,"code":"import org.apache.kafka.streams.KafkaStreams;\nimport org.apache.kafka.streams.StreamsBuilder;\nimport org.apache.kafka.streams.kstream.KStream;\nimport org.apache.kafka.streams.kstream.KStreamBuilder;\n\npublic class KafkaStreamsExample {\n    public static void main(String[] args) {\n        StreamsBuilder builder = new StreamsBuilder();\n        KStream<String, String> source = builder.stream(\"source-topic\");\n        source.to(\"sink-topic\");\n\n        KafkaStreams streams = new KafkaStreams(builder.build(), new Properties());\n        streams.start();\n    }\n}","translations":{"it":["Cosa ottiene la seguente policy AWS IAM?","Produttore Kafka","Kafka AdminClient","Kafka Zookeeper","Kafka Streams"]}}]